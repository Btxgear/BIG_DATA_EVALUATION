version: '3.9'

services:
  hadoop-worker1:
    image: madjidtaoualit/hadoop-cluster:latest
    hostname: hadoop-worker1
    container_name: hadoop-worker1
    ports:
      - "8040:8042"
    networks:
      - hadoop
    tty: true
    stdin_open: true
    command: /bin/bash -c "service ssh start && tail -f /dev/null"  # Laisse le worker actif

  hadoop-worker2:
    image: madjidtaoualit/hadoop-cluster:latest
    hostname: hadoop-worker2
    container_name: hadoop-worker2
    ports:
      - "8041:8042"
    networks:
      - hadoop
    tty: true
    stdin_open: true
    command: /bin/bash -c "service ssh start && tail -f /dev/null"  # Laisse le worker actif

  hadoop-master:
    image: madjidtaoualit/hadoop-cluster:latest
    hostname: hadoop-master
    container_name: hadoop-master
    ports:
      - "9870:9870"
      - "8088:8088"
      - "7077:7077"
      - "16010:16010"
      - "5005:5000" # Port pour l'API Flask
    networks:
      - hadoop
    tty: true
    stdin_open: true
    volumes:
      - ./start-up-script/start-up.sh:/root/start-up.sh
      - ./data/netflix-data.csv:/root/netflix-data.csv
      - ./back/api/bigdata_evaluation.py:/root/api/bigdata_evaluation.py
      - ./jar/netflix_processing.jar:/root/netflix_processing.jar
    entrypoint: /bin/bash -c "chmod +x /root/start-up.sh && /root/start-up.sh && tail -f /dev/null"

  front:
    image: nginx:alpine
    container_name: front
    networks:
      - hadoop
    ports:
      - "80:80"
    volumes:
      - ./front:/usr/share/nginx/html

networks:
  hadoop:
    driver: bridge